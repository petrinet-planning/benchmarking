{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "# print(\"In module products sys.path[0], __package__ ==\", sys.path[0], __package__)\n",
    "\n",
    "# import os\n",
    "import os.path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from typing import Callable\n",
    "import re\n",
    "from math import floor\n",
    "import statistics\n",
    "\n",
    "from test_runner import *\n",
    "from test_runner.translators import *\n",
    "from test_runner.analysers import SearchResult\n",
    "\n",
    "\n",
    "# from test_runner import TestCase, BaseTestRunner, LiftedPlanningRunner, GroundedPlanningRunner\n",
    "# from test_runner.tapaal_caller import QueryResult\n",
    "\n",
    "from parse_results import translator_result_type, search_result_type#, load_translator_results, load_search_results, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downward = circle red\n",
    "# grounded = square green\n",
    "# lifted = triangle blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_collection import result_collection, result_container\n",
    "\n",
    "\n",
    "infinite = float(\"inf\")\n",
    "results_dir = \"../results_p9\"\n",
    "plot_save_dir = \"../results_p9/plots\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "results_path = \"../results_p9\"\n",
    "\n",
    "domain_sub_range = range(1, 32)\n",
    "\n",
    "\n",
    "results = result_container()\n",
    "\n",
    "\n",
    "def load_translator_results() -> translator_result_type:\n",
    "    with open(os.path.join(results_path, f\"translator_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def load_search_results() -> search_result_type:\n",
    "    with open(os.path.join(results_path, f\"search_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "_loaded_translator_results: translator_result_type = load_translator_results()\n",
    "_loaded_search_results: search_result_type = load_search_results()\n",
    "\n",
    "\n",
    "# Translator -> domain -> result[]\n",
    "translator_results_str_lookup: dict[str, dict[str, \"BaseTranslator\"]] = dict()\n",
    "\n",
    "\n",
    "# Translator Results\n",
    "for translator, domains in _loaded_translator_results.items():\n",
    "    translator_results_str_lookup[translator.name] = dict()\n",
    "    for domain, test_results in domains.items():\n",
    "        translator_results_str_lookup[translator.name][domain.name] = test_results\n",
    "\n",
    "\n",
    "# Search Results\n",
    "domain_regex = re.compile(r\"^(?P<domain>.+?)_(?P<id>\\d\\d)$\", re.MULTILINE)\n",
    "for translator, translator_results in _loaded_search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for searcher, search_results in test_results.items():\n",
    "\n",
    "            domain_name = domain_regex.match(test_case.name)[\"domain\"]\n",
    "            domain_sub_id = int(domain_regex.match(test_case.name)[\"id\"])\n",
    "\n",
    "            specific_translator_results = translator_results_str_lookup[translator.name][test_case.name]\n",
    "            specific_searcher_results = search_results\n",
    "\n",
    "\n",
    "            if (\n",
    "                translator.name in results.translators and\n",
    "                domain_name     in results.translators[translator.name].domains and\n",
    "                searcher.name   in results.translators[translator.name].domains[domain_name].searchers\n",
    "            ):\n",
    "                results.translators[translator.name].domains[domain_name].searchers[searcher.name].set(domain_sub_id, specific_translator_results, specific_searcher_results)\n",
    "            \n",
    "            else:\n",
    "\n",
    "                _result_collection = result_collection(domain_sub_range)\n",
    "                _result_collection.set(domain_sub_id, specific_translator_results, specific_searcher_results)\n",
    "\n",
    "                # results.set(translator.name, domain.name, searcher.name, _result_collection)\n",
    "                results.set(translator.name, domain_name, searcher.name, _result_collection)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for translator_name, translator_results in results.translators.items():\n",
    "    for domain_name, test_results in translator_results.domains.items():\n",
    "        for searcher_name, result_collection in test_results.searchers.items():\n",
    "\n",
    "            if searcher_name == \"no_color_optimizations\":\n",
    "                result_collection.style = None\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"color_rpfs\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#332288\"\n",
    "                continue\n",
    "            \n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"colored\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#117733\"\n",
    "                continue         \n",
    "               \n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"colored_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#44AA99\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"hier_rpfs\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#88CCEE\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"hier_v1\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#DDCC77\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"hier_v1_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#CC6677\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchyv2\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"hier_v2\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#ADD8E6\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchyv2\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"hier_v2_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#00008B\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"grounded\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"grounded\"\n",
    "                result_collection.style = \"v-\"\n",
    "                result_collection.color=\"#AA4499\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"downward\" and searcher_name == \"lama_first\":\n",
    "                result_collection.display_name = \"downward\"\n",
    "                result_collection.style = \"o-\"\n",
    "                result_collection.color=\"#882255\"\n",
    "                continue\n",
    "\n",
    "            print(\"Unstyled config\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "reductions = dict()\n",
    "domains_per_reduction = dict()\n",
    "\n",
    "\n",
    "for translator_name, translator_results in results.translators.items():\n",
    "    # if translator_name == \"colored\": continue\n",
    "    # if translator_name == \"colored_hierarchy\": continue\n",
    "    if translator_name == \"grounded\": continue\n",
    "    if translator_name == \"downward\": continue\n",
    "\n",
    "    for searcher_name, searcher_results in translator_results.searchers.items():\n",
    "        for domain_name, result_collections in searcher_results.domains.items():\n",
    "\n",
    "            for domain_sub_id, search_results in enumerate(result_collections.search_results):\n",
    "                \n",
    "                if len(result_collection.search_results) == 0:\n",
    "                    continue\n",
    "\n",
    "                search_result = result_collection.search_results[0]\n",
    "                if hasattr(search_result, \"reductions_applied\"):\n",
    "                    for (rule_id, count) in search_result.reductions_applied.items():\n",
    "                        if not rule_id in reductions:\n",
    "                            reductions[rule_id] = 0\n",
    "                            domains_per_reduction[rule_id] = list()\n",
    "                        \n",
    "                        reductions[rule_id] += count\n",
    "                        if count > 0:\n",
    "                            domains_per_reduction[rule_id].append(f\"{translator.name}:{domain_name.name}_{domain_sub_id}\")\n",
    "    \n",
    "    #print(test_case.name)\n",
    "for (reduction_id, count) in reductions.items():\n",
    "    print(str.ljust(f\"{reduction_id}: {count}\", 30) + f\"{domains_per_reduction[rule_id]}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# -r 3 2,3,4,6,8,11,12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview Plot\n",
    "plot = run config\n",
    "\n",
    "x = IPC instance id\n",
    "\n",
    "y = median time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_runner.analysers import TranslatorResult, SearchResult\n",
    "from result_collection import result_collection\n",
    "\n",
    "# Generic\n",
    "\n",
    "\n",
    "def median_reduction(translator_reduction: Callable[[TranslatorResult], float], searcher_reduction: Callable[[SearchResult], float]) -> Callable[[result_collection], list[float]]:\n",
    "    def reduction(rc: result_collection) -> list[float]:\n",
    "        translator_vals_per_task = [[translator_reduction(x) for x in translator_results] for translator_results in rc.translator_results]\n",
    "        search_vals_per_task     = [[searcher_reduction(x) for x in search_results] for search_results in rc.search_results]\n",
    "\n",
    "\n",
    "        translator_numeric = [statistics.median(results) if len(results) > 0 else infinite for results in translator_vals_per_task]\n",
    "        searcher_numeric   = [statistics.median(results) if len(results) > 0 else infinite for results in search_vals_per_task]\n",
    "\n",
    "\n",
    "        added = [ x + y for x, y in zip(translator_numeric, searcher_numeric)]\n",
    "\n",
    "        return added\n",
    "    \n",
    "    return reduction\n",
    "\n",
    "\n",
    "def minimum_reduction(translator_reduction: Callable[[TranslatorResult], float], searcher_reduction: Callable[[SearchResult], float]) -> Callable[[result_collection], list[float]]:\n",
    "    def reduction(rc: result_collection) -> list[float]:\n",
    "        translator_vals_per_task = [[translator_reduction(x) for x in translator_results] for translator_results in rc.translator_results]\n",
    "        search_vals_per_task     = [[searcher_reduction(x) for x in search_results] for search_results in rc.search_results]\n",
    "\n",
    "\n",
    "        translator_numeric = [statistics.median(results) if len(results) > 0 else infinite for results in translator_vals_per_task]\n",
    "        searcher_numeric   = [statistics.median(results) if len(results) > 0 else infinite for results in search_vals_per_task]\n",
    "\n",
    "\n",
    "        added = [ x + y for x, y in zip(translator_numeric, searcher_numeric)]\n",
    "\n",
    "        return added\n",
    "    \n",
    "    return reduction\n",
    "\n",
    "\n",
    "def median_search_property(prop_name: str) -> Callable[[result_collection], list[float]]:\n",
    "    return median_reduction(\n",
    "        lambda res: 0,\n",
    "        lambda res: res.get(prop_name, infinite)\n",
    "    )\n",
    "\n",
    "\n",
    "# Time\n",
    "\n",
    "median_time_total = median_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "minimum_time_search = minimum_reduction(\n",
    "    lambda res: 0,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "median_time_translate = minimum_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.valid_translation else infinite,\n",
    "    lambda res: 0\n",
    ")\n",
    "\n",
    "median_time_search = median_reduction(\n",
    "    lambda res: 0,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "minimum_time_total = minimum_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# class XTickFormater(matplotlib.ticker.Formatter):\n",
    "#     def format_ticks(values):\n",
    "#         return [f\"P{v+1}\" for v in values]\n",
    "# xtickFormatter = XTickFormater()\n",
    "# Formerly 1+ to x axis\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_overview_cactus_plot(name: str, description: str, reduction: Callable[[\"result_collection\"], list[float]]):\n",
    "    fig_rows = 5\n",
    "    fig_cols = 5\n",
    "\n",
    "\n",
    "    # Domain -> searcher -> translator -> IPCMedian[] \n",
    "    # search_results_domain_searcher_translator_test_case\n",
    "\n",
    "\n",
    "    i=1\n",
    "    # scale = 4.5\n",
    "    scale = 10\n",
    "    # fig = plt.figure(figsize=(2.3*scale, scale))\n",
    "    fig = plt.figure(figsize=(scale, scale))\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "\n",
    "    for domain_name, domain_results in results.domains.items():\n",
    "\n",
    "\n",
    "        subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "        max_y = 0\n",
    "        axis = plt.gca()\n",
    "\n",
    "        for translator_name, translator_results in domain_results.translators.items():\n",
    "            for searcher_name, _result_collection in translator_results.searchers.items():\n",
    "\n",
    "                #plt.plot(list(median_times.values())[0], 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                # plt.plot(median_times, 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                reduced_data = reduction(_result_collection)\n",
    "                if _result_collection.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "                    \n",
    "                    plt.plot(reduced_data, _result_collection.style, color=_result_collection.color, label=_result_collection.display_name)#f\"{translator.name}({searcher.name})\")\n",
    "\n",
    "                    #plt.xticks(range(0,30), [f\"P{x+1}\" for x in range(0,30)])\n",
    "                    # plt.xlabels([f\"P{x+1}\" for x in range(0,30)])\n",
    "                    #(xlim_min, xlim_max) = axis.get_xlim()\n",
    "                    #axis.set_xlim([xlim_min, min(xlim_max, 30)])\n",
    "\n",
    "                    # yaxis begins at 0\n",
    "                    #(ylim_min, ylim_max) = axis.get_ylim()\n",
    "                    max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                    subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                    subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "                    # subplt.axes.ticklabel_format(xtickFormatter, \"x\")\n",
    "                    # fig.gca().axes.xaxis.format_ticks(xtickFormatter)\n",
    "                #yticks = range(0,30)\n",
    "                #plt.yticks(yticks, step=1)\n",
    "#                ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # Integer x axis\n",
    "\n",
    "        # axis.set_ylim(bottom=0)\n",
    "\n",
    "        plt.title(domain_name)\n",
    "        #plt.title(f'{description} - {test_case.name}')\n",
    "        plt.gca().legend(loc='best')\n",
    "        plt.xlabel('Task index')\n",
    "        if (i-1)%3 == 0:\n",
    "            plt.ylabel(description)\n",
    "        subplt.set_yscale(\"log\")\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_save_dir, f\"{name}.png\"))\n",
    "\n",
    "\n",
    "\n",
    "make_overview_cactus_plot(\"overview_med_time_total\", 'Median Time (sec)', median_time_total)\n",
    "make_overview_cactus_plot(\"overview_min_time_total\", \"Min Total Time\", minimum_time_total)\n",
    "make_overview_cactus_plot(\"overview_min_time_search\", \"Min Search Time\", minimum_time_search)\n",
    "\n",
    "\n",
    "\n",
    "# #make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "# #make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "# make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "# #make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "# #make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "# make_overview_cactus_plot(\"overview_verification_time\", \"Median Verification Time\", lambda res: res.median_verification_time)\n",
    "# # make_overview_cactus_plot(\"overview_unfolded_places\", \"Unfolded Place Count\", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "# # make_overview_cactus_plot(\"overview_unfolded_transitions\", \"Unfolded Transition Count\", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Domain Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_domain_cactus_plot(name: str, description: str, rows, cols, reductions: list[tuple[str, Callable[[\"result_collection\"], list[float]]]]):\n",
    "    fig_rows = rows #1\n",
    "    fig_cols = cols #len(reductions)\n",
    "\n",
    "    scale = 10\n",
    "\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "    for (domain_name, domain_results) in results.domains.items():\n",
    "        fig = plt.figure(figsize=(scale, scale))\n",
    "        i=1\n",
    "        for (reduction_name, reduction) in reductions:\n",
    "            subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "            max_y = 0\n",
    "            axis = plt.gca()\n",
    "            for (translator, translator_results) in domain_results.translators.items():\n",
    "                for (searcher, resultCollections) in translator_results.searchers.items():\n",
    "                    reduced_data = reduction(resultCollections)\n",
    "                    if resultCollections.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "\n",
    "                        # if searcher.display_name != \"color_rpfs_safe_no_timeout\" and searcher.display_name != \"hier_rpfs_safe_no_timeout\" and searcher.display_name != \"grounded\":\n",
    "                        #     continue\n",
    "                        \n",
    "                        plt.plot(reduced_data, resultCollections.style, color=resultCollections.color, label=resultCollections.display_name)\n",
    "\n",
    "                        max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                        subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                        subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "            plt.title(reduction_name)\n",
    "            #plt.title(f'{description} - {test_case.name}')\n",
    "            plt.gca().legend(loc='best')\n",
    "            plt.xlabel('Task index')\n",
    "            if (i-1)%4 == 0:\n",
    "                plt.ylabel(domain_name)\n",
    "            subplt.set_yscale(\"log\")\n",
    "            i += 1\n",
    "\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_save_dir, f\"{name}_{domain_name}.png\"))\n",
    "\n",
    "#make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "#make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "#make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "\n",
    "reductions:list[tuple[str, Callable[[\"result_collection\"], float]]] = {\n",
    "    ('Median Time (sec)', median_time_total),\n",
    "    (\"Median Search Time (sec)\", median_time_search),\n",
    "    (\"Median Translate Time (sec)\", median_time_translate),\n",
    "    # (\"Median Verification Time\",  median_search_property(\"time_verification\")),\n",
    "    (\"Unfolded Place Count\", median_search_property(\"place_count_after_reduction\")),\n",
    "    (\"Unfolded Transition Count\", median_search_property(\"transition_count_after_reduction\"))\n",
    "}\n",
    "\n",
    "make_domain_cactus_plot(\"name\", \"description\", 3, 2, reductions)\n",
    "# make_domain_cactus_plot(\"name\", \"description\", 2, 2, reductions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_time              \", \"Min Total Time                     \", lambda res: res.min_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# min_verificaiton_time \", 'Min verification time              ', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# time                  \", 'Median Time (sec)                  ', lambda res: res.median_time)\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "# make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "def get_median_time_minus_unfolding(res: ResultCollection):\n",
    "                \n",
    "                \n",
    "                if translator.name==\"colored\":\n",
    "                \n",
    "                plan_lengths = [len(result.plan.actions) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_trace_length = statistics.median(plan_lengths)\n",
    "\n",
    "                time_unfolding = [result[\"time_unfolding\"] if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_unfolding_time = statistics.median(time_unfolding)\n",
    "\n",
    "                resultCollection.median_time_minus_unfolding = statistics.median([(result.time.seconds_system + result.time.seconds_user - result[\"time_unfolding\"]) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ])\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median unfolding Time (sec)        ', lambda res: res.median_unfolding_time)\n",
    "\n",
    "\n",
    "# verification_time     \", \"Median Verification Time           \", lambda res: res.median_verification_time)\n",
    "\n",
    "\n",
    "# unfolded_places       \", \"Unfolded Place Count               \", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "\n",
    "\n",
    "# unfolded_transitions  \", \"Unfolded Transition Count          \", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator -> runner\n",
    "total_plans = dict()\n",
    "unique_solvers = dict()\n",
    "fastest_solvers = dict()\n",
    "\n",
    "def count_filter(id_tuple):\n",
    "    domain_name, translator_name, searcher_name, task_iterator = id_tuple\n",
    "\n",
    "    if translator_name == \"colored_hierarchyv2\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "        return True\n",
    "    \n",
    "    if translator_name == \"grounded\":\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def show_header(header_id):\n",
    "    translator_name, searcher_name = header_id\n",
    "    return count_filter((\"\", translator_name, searcher_name, \"\"))\n",
    "\n",
    "\n",
    "def count_total_plan(id_tuple):\n",
    "    domain_name, translator_name, searcher_name, task_iterator = id_tuple\n",
    "    id = (translator_name, searcher_name)\n",
    "    total_plans[id] = total_plans.get(id, 0) + 1\n",
    "\n",
    "def count_unique_solver(id_tuple):\n",
    "    domain_name, translator_name, searcher_name, task_iterator = id_tuple\n",
    "    id = (translator_name, searcher_name)\n",
    "    unique_solvers[id] = unique_solvers.get(id, 0) + 1\n",
    "    \n",
    "def count_fastest_solvers(id_tuple):\n",
    "    domain_name, translator_name, searcher_name, task_iterator = id_tuple\n",
    "    id = (translator_name, searcher_name)\n",
    "    fastest_solvers[id] = fastest_solvers.get(id, 0) + 1\n",
    "\n",
    "\n",
    "#domain_counter = 0\n",
    "for domain_name, domain_results in results.domains.items():\n",
    "    if domain_name == \"openstacks\":\n",
    "        continue\n",
    "\n",
    "    #if domain_counter > 2:\n",
    "    #    break\n",
    "    #domain_counter += 1\n",
    "\n",
    "    for task_iterator in range(1, 31):\n",
    "        \n",
    "        fastest_solve = infinite\n",
    "        fastest_solver = None\n",
    "\n",
    "        solvers = []\n",
    "\n",
    "        for translator_name, translator_results in domain_results.translators.items():\n",
    "            for searcher_name, resultCollection in translator_results.searchers.items():\n",
    "                translator_result = resultCollection.translator_results[task_iterator]\n",
    "                search_result = resultCollection.search_results[task_iterator]\n",
    "\n",
    "                result_id = (domain_name, translator_name, searcher_name, task_iterator)\n",
    "                if not count_filter(result_id):\n",
    "                    continue\n",
    "\n",
    "                time = median_time_total(resultCollection)[task_iterator]\n",
    "\n",
    "                if time < infinite:\n",
    "                    count_total_plan(result_id)\n",
    "\n",
    "                    solvers.append(result_id)\n",
    "\n",
    "                    if time < fastest_solve:\n",
    "                        fastest_solve = time\n",
    "                        fastest_solver = result_id\n",
    "\n",
    "        ## End of task\n",
    "        if len(solvers) == 1:\n",
    "            count_unique_solver(solvers[0])\n",
    "\n",
    "        if fastest_solve < infinite:\n",
    "            count_fastest_solvers(fastest_solver)\n",
    "\n",
    "\n",
    "order = [\n",
    "    ('colored_hierarchyv2', 'rpfs_safe_reductions'),\n",
    "    ('colored_hierarchyv2', 'rpfs_safe_reductions_unlimited_intervals'),\n",
    "    ('colored', 'rpfs_safe_reductions'),\n",
    "    ('colored', 'rpfs_safe_reductions_unlimited_intervals'),\n",
    "    ('grounded', 'rpfs'),\n",
    "    ('downward', 'lama_first')\n",
    "]\n",
    "\n",
    "\n",
    "format = \"& {:<20}\"\n",
    "\n",
    "def printDict(name, data, default):\n",
    "    out = \"{:<15}\".format(name)\n",
    "    for id in order:\n",
    "        if not show_header(id):\n",
    "            continue\n",
    "\n",
    "        out += format.format(data.get(id, default))\n",
    "    \n",
    "\n",
    "    print(out)\n",
    "\n",
    "\n",
    "header = \"\"\n",
    "for id in order:\n",
    "    if not show_header(id):\n",
    "        continue\n",
    "\n",
    "    header += format.format(str(id))\n",
    "\n",
    "\n",
    "\n",
    "print(\"```\")\n",
    "print(header)\n",
    "printDict(\"plans found\", total_plans, 0)\n",
    "printDict(\"Unique Plans\", unique_solvers, 0)\n",
    "printDict(\"Fastest Plan\", fastest_solvers, 0)\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "solved_median_time_total = median_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if (res.result_status == QueryResultStatus.satisfied  or res.result_status == QueryResultStatus.unsolvable) else infinite\n",
    ")\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "styles = []\n",
    "\n",
    "for domain_name, domain_results in results.domains.items():\n",
    "    tapaal = domain_results.translators[\"nothing\"].searchers[\"Tapaal\"]\n",
    "    enhsp = domain_results.translators[\"cpn\"].searchers[\"CpnToEnhsp\"]\n",
    "\n",
    "    tapaal_time = solved_median_time_total(tapaal)\n",
    "    enshp_time = solved_median_time_total(enhsp)\n",
    "\n",
    "    for i in range(0, 31):\n",
    "        # Experiment actually exists if Tapaal had a translation\n",
    "        if not tapaal.translator_results[i]:\n",
    "            continue\n",
    "\n",
    "        if tapaal_time[i] == infinite and enshp_time[i] == infinite:\n",
    "            continue # Would just be in top right\n",
    "\n",
    "        status_provider = tapaal.search_results[i][0]\n",
    "        if status_provider.result_status == QueryResultStatus.error:\n",
    "            status_provider = enhsp.search_results[i][0]\n",
    "\n",
    "        \n",
    "        solvable = status_provider.result_status == QueryResultStatus.satisfied\n",
    "        unsolvable = status_provider.result_status == QueryResultStatus.unsolvable\n",
    "        #unknown = status_provider.result_status == QueryResultStatus.unknown\n",
    "        error = status_provider.result_status == QueryResultStatus.error\n",
    "        warning = enhsp.search_results[i][0].plan_warning\n",
    "\n",
    "        style = (\n",
    "            (\"x\", \"#A00\") if warning else\n",
    "            (\"^\", \"#0A0\") if solvable else\n",
    "            (\"H\", \"#00A\") if unsolvable else\n",
    "            #(\"o\", \"#222\") if unknown else\n",
    "            (\"s\", \"#FF0\") if error else\n",
    "                None\n",
    "        )\n",
    "        if not style:\n",
    "            raise \"Unhandled State\"\n",
    "        \n",
    "        styles.append(style)\n",
    "\n",
    "        x.append(tapaal_time[i])\n",
    "        y.append(enshp_time[i])\n",
    "\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_x = max([i for i in x if i != infinite])\n",
    "max_y = max([i for i in y if i != infinite])\n",
    "max_max = max(max_x, max_y)\n",
    "\n",
    "unsolvedVal = 10**5 # max_max * 3\n",
    "plot_max = max(max_max, unsolvedVal)\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(scale, scale))\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "shapes, colors = zip(*styles)\n",
    "\n",
    "ax.plot([0, plot_max], [0, plot_max])\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plotX = x[i] if x[i] != infinite else unsolvedVal\n",
    "    plotY = y[i] if y[i] != infinite else unsolvedVal\n",
    "\n",
    "    ax.scatter(plotX, plotY, c=colors[i], marker=shapes[i])#, vmin=0, vmax=100)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Total seconds TAPAAL\")\n",
    "plt.ylabel(\"Total seconds ENHSP\")\n",
    "\n",
    "ax.set_xlim(xmin=0.001, xmax=plot_max)\n",
    "ax.set_ylim(ymin=0.001, ymax=plot_max)\n",
    "\n",
    "\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[-2] = 'Undecided'\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "labels[-2] = 'Undecided'\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "\n",
    "warning    = Line2D([0], [0], label='warning',      marker=\"x\", c=\"#A00\", markersize=10, markerfacecolor=\"#A00\", linestyle='')\n",
    "solvable   = Line2D([0], [0], label='Satisfiable',  marker=\"^\", c=\"#0A0\", markersize=10, markerfacecolor=\"#0A0\", linestyle='')\n",
    "unsolvable = Line2D([0], [0], label='Unsolvable',   marker=\"H\", c=\"#00A\", markersize=10, markerfacecolor=\"#00A\", linestyle='')\n",
    "\n",
    "\n",
    "plt.legend(handles=[warning, solvable, unsolvable], loc=\"lower right\")\n",
    "\n",
    "# plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_save_dir, f\"cpnToPddlResults_Total.png\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

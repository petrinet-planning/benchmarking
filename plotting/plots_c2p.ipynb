{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "# print(\"In module products sys.path[0], __package__ ==\", sys.path[0], __package__)\n",
    "\n",
    "# import os\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from typing import Callable\n",
    "import re\n",
    "from math import floor\n",
    "import statistics\n",
    "from result_collection import result_collection\n",
    "\n",
    "from test_runner import *\n",
    "from test_runner.translators import *\n",
    "from test_runner.analysers import SearchResult, QueryResultStatus\n",
    "\n",
    "\n",
    "# from test_runner import TestCase, BaseTestRunner, LiftedPlanningRunner, GroundedPlanningRunner\n",
    "# from test_runner.tapaal_caller import QueryResult\n",
    "\n",
    "from parse_results import translator_result_type, search_result_type#, load_translator_results, load_search_results, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downward = circle red\n",
    "# grounded = square green\n",
    "# lifted = triangle blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_collection import result_collection, result_container\n",
    "\n",
    "\n",
    "infinite = float(\"inf\")\n",
    "results_dir = \"../results_c2p\"\n",
    "plot_save_dir = \"../results_c2p/plots\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "results_path = \"../results_c2p\"\n",
    "\n",
    "domain_sub_range = range(1, 32)\n",
    "\n",
    "\n",
    "results = result_container()\n",
    "\n",
    "\n",
    "def load_translator_results() -> translator_result_type:\n",
    "    with open(os.path.join(results_path, f\"translator_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def load_search_results() -> search_result_type:\n",
    "    with open(os.path.join(results_path, f\"search_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "_loaded_translator_results: translator_result_type = load_translator_results()\n",
    "_loaded_search_results: search_result_type = load_search_results()\n",
    "\n",
    "\n",
    "# Translator -> domain -> result[]\n",
    "translator_results_str_lookup: dict[str, dict[str, \"BaseTranslator\"]] = dict()\n",
    "\n",
    "\n",
    "# Translator Results\n",
    "for translator, domains in _loaded_translator_results.items():\n",
    "    translator_results_str_lookup[translator.name] = dict()\n",
    "    for domain, test_results in domains.items():\n",
    "        translator_results_str_lookup[translator.name][domain.name] = test_results\n",
    "\n",
    "\n",
    "# Search Results\n",
    "domain_regex = re.compile(r\"^(?P<domain>.+?) - .+?(?P<id>\\d\\d)$\", re.MULTILINE)\n",
    "for translator, translator_results in _loaded_search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for searcher, search_results in test_results.items():\n",
    "\n",
    "            domain_name = domain_regex.match(test_case.name)[\"domain\"]\n",
    "            domain_sub_id = int(domain_regex.match(test_case.name)[\"id\"])\n",
    "\n",
    "            specific_translator_results = translator_results_str_lookup[translator.name][test_case.name]\n",
    "            specific_searcher_results = search_results\n",
    "\n",
    "\n",
    "            if (\n",
    "                translator.name in results.translators and\n",
    "                domain_name     in results.translators[translator.name].domains and\n",
    "                searcher.name   in results.translators[translator.name].domains[domain_name].searchers\n",
    "            ):\n",
    "                results.translators[translator.name].domains[domain_name].searchers[searcher.name].set(domain_sub_id, specific_translator_results, specific_searcher_results)\n",
    "            \n",
    "            else:\n",
    "\n",
    "                _result_collection = result_collection(domain_sub_range)\n",
    "                _result_collection.set(domain_sub_id, specific_translator_results, specific_searcher_results)\n",
    "\n",
    "                # results.set(translator.name, domain.name, searcher.name, _result_collection)\n",
    "                results.set(translator.name, domain_name, searcher.name, _result_collection)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for translator_name, translator_results in results.translators.items():\n",
    "    for domain_name, test_results in translator_results.domains.items():\n",
    "        for searcher_name, result_collection in test_results.searchers.items():\n",
    "\n",
    "            if searcher_name == \"no_color_optimizations\":\n",
    "                result_collection.style = None\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"color_rpfs\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#332288\"\n",
    "                continue\n",
    "            \n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"colored\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#117733\"\n",
    "                continue         \n",
    "               \n",
    "            if translator_name == \"colored\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"colored_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#44AA99\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"hier_rpfs\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#88CCEE\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"hier_v1\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#DDCC77\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchy\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"hier_v1_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#CC6677\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchyv2\" and searcher_name == \"rpfs_safe_reductions\":\n",
    "                result_collection.display_name = \"hier_v2\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#ADD8E6\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"colored_hierarchyv2\" and searcher_name == \"rpfs_safe_reductions_unlimited_intervals\":\n",
    "                result_collection.display_name = \"hier_v2_NT\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#00008B\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"grounded\" and searcher_name == \"rpfs\":\n",
    "                result_collection.display_name = \"grounded\"\n",
    "                result_collection.style = \"v-\"\n",
    "                result_collection.color=\"#AA4499\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"downward\" and searcher_name == \"lama_first\":\n",
    "                result_collection.display_name = \"downward\"\n",
    "                result_collection.style = \"o-\"\n",
    "                result_collection.color=\"#882255\"\n",
    "                continue\n",
    "\n",
    "            if translator_name == \"nothing\" and searcher_name == \"Tapaal\":\n",
    "                result_collection.display_name = \"tapaal\"\n",
    "                result_collection.style = \"s-\"\n",
    "                result_collection.color=\"#332288\"\n",
    "                continue\n",
    "            \n",
    "            if translator_name == \"cpn\" and searcher_name == \"CpnToEnhsp\":\n",
    "                result_collection.display_name = \"enhsp\"\n",
    "                result_collection.style = \"o-\"\n",
    "                result_collection.color=\"#882255\"\n",
    "                continue\n",
    "\n",
    "            print(\"Unstyled config\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "totalAgreedSolvable = 0\n",
    "tapaalFasterSearchSolvable = 0\n",
    "tapaalFasterTotalSolvable = 0\n",
    "enhspFasterSearchSolvable = 0\n",
    "enhspFasterTotalSolvable = 0\n",
    "totalAgreedUnsolvable = 0\n",
    "\n",
    "tapaalFasterSearchUnsolvable = 0\n",
    "tapaalFasterTotalUnsolvable = 0\n",
    "enhspFasterSearchUnsolvable = 0\n",
    "enhspFasterTotalUnsolvable = 0\n",
    "\n",
    "possiblyInvalidSolutionsInAgreed = 0\n",
    "possiblyInvalidSolutionsTotal = 0\n",
    "\n",
    "solvedTotalTapaal = 0\n",
    "solvedTotalEnhsp = 0\n",
    "unsolvedTotalTapaal = 0\n",
    "unsolvedTotalEnhsp = 0\n",
    "\n",
    "tapaal_undecided = 0\n",
    "enhsp_undecided = 0\n",
    "tapaal_error = 0\n",
    "enhsp_error = 0\n",
    "\n",
    "\n",
    "satisfiable_uniquely_solved_tapaal = 0\n",
    "satisfiable_uniquely_solved_enhsp = 0\n",
    "unsolvable_uniquely_solved_tapaal = 0\n",
    "unsolvable_uniquely_solved_enhsp = 0\n",
    "\n",
    "\n",
    "satisfiable_uniquely_solved_tapaal_other_timed_out = 0\n",
    "satisfiable_uniquely_solved_enhsp_other_timed_out = 0\n",
    "unsolvable_uniquely_solved_tapaal_other_timed_out = 0\n",
    "unsolvable_uniquely_solved_enhsp_other_timed_out = 0\n",
    "\n",
    "tapaal_timed_out = 0\n",
    "enhsp_timed_out = 0\n",
    "\n",
    "\n",
    "enhspErrors = dict()\n",
    "enhspErrors[\"OutOfMemory\"] = 0\n",
    "enhspErrors[\"StackOverflow\"] = 0\n",
    "enhspErrors[\"SyntaxError\"] = 0\n",
    "enhspErrors[\"TranslationFailed\"] = 0\n",
    "enhspErrors[\"NullPointerException\"] = 0\n",
    "\n",
    "\n",
    "enhspErrors_translator = dict()\n",
    "enhspErrors_translator[\"exprTooDeep_stringBuilder\"] = 0\n",
    "enhspErrors_translator[\"exprTooDeep_rawExpr\"] = 0\n",
    "enhspErrors_translator[\"success\"] = 0\n",
    "enhspErrors_translator[\"OutOfMemory\"] = 0\n",
    "enhspErrors_translator[\"StackOverflow\"] = 0\n",
    "enhspErrors_translator[\"NullPointerException\"] = 0\n",
    "enhspErrors_translator[\"PnmlParserError\"] = 0\n",
    "\n",
    "\n",
    "total_domains = 0\n",
    "total_queries = 0\n",
    "\n",
    "for domain_name, domain_results in results.domains.items():\n",
    "    total_domains += 1\n",
    "\n",
    "    success_states = dict()\n",
    "\n",
    "    for translator_name, translator_results in domain_results.translators.items():\n",
    "        for searcher_name, searcher_results in translator_results.searchers.items():\n",
    "\n",
    "            if translator_name==\"nothing\" and searcher_name==\"Tapaal\":\n",
    "                \n",
    "                success_states[\"tapaal\"] = [\n",
    "                    (searcher_result[0].result_status,\n",
    "                        translator_result[0].time.seconds_system+translator_result[0].time.seconds_user,\n",
    "                        searcher_result[0].time.seconds_system+searcher_result[0].time.seconds_user,\n",
    "                        translator_result[0],\n",
    "                        searcher_result[0]\n",
    "                        ) if searcher_result else None\n",
    "                    for (translator_result, searcher_result) in zip(searcher_results.translator_results, searcher_results.search_results)\n",
    "                ]\n",
    "\n",
    "                continue\n",
    "\n",
    "            if translator_name==\"cpn\" and searcher_name==\"CpnToEnhsp\":\n",
    "\n",
    "                success_states[\"enhsp\"] = [\n",
    "                    (searcher_result[0].result_status,\n",
    "                        translator_result[0].time.seconds_system+translator_result[0].time.seconds_user,\n",
    "                        searcher_result[0].time.seconds_system+searcher_result[0].time.seconds_user,\n",
    "                        translator_result[0],\n",
    "                        searcher_result[0]\n",
    "                        ) if searcher_result else None\n",
    "                    for (translator_result, searcher_result) in zip(searcher_results.translator_results, searcher_results.search_results)\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "    tapaal_results = success_states[\"tapaal\"]\n",
    "    enhsp_results = success_states[\"enhsp\"]\n",
    "\n",
    "    #if tapaal_results != enhsp_results:\n",
    "    disagreeCount = 0\n",
    "    agreedSolvable = 0\n",
    "    agreedUnsolvable = 0\n",
    "    for i in range(0,31):\n",
    "        if (not tapaal_results[i]) and (not enhsp_results[i]):\n",
    "            continue\n",
    "\n",
    "        total_queries += 1\n",
    "\n",
    "        tapaal_result, tapaal_translate_time, tapaal_search_time, tapaal_translator_result, tapaal_search_result = tapaal_results[i] #if tapaal_results[i] else (None, infinite, infinite, None)\n",
    "        enhsp_result, enhsp_translate_time, enhsp_search_time, enhsp_translator_result, enhsp_search_result = enhsp_results[i] #if enhsp_results[i] else (None, infinite, infinite, None)\n",
    "\n",
    "        # Disagree on solvable or not\n",
    "        if ( tapaal_result == QueryResultStatus.satisfied and enhsp_result == QueryResultStatus.unsolvable or\n",
    "             tapaal_result == QueryResultStatus.unsolvable and enhsp_result == QueryResultStatus.satisfied):\n",
    "             disagreeCount += 1\n",
    "\n",
    "        if tapaal_result == QueryResultStatus.satisfied:\n",
    "            solvedTotalTapaal += 1\n",
    "        if enhsp_result == QueryResultStatus.satisfied and not enhsp_search_result.plan_warning:\n",
    "            solvedTotalEnhsp += 1\n",
    "\n",
    "        if tapaal_result == QueryResultStatus.unsolvable:\n",
    "            unsolvedTotalTapaal += 1\n",
    "        if enhsp_result == QueryResultStatus.unsolvable and not enhsp_search_result.plan_warning:\n",
    "            unsolvedTotalEnhsp += 1\n",
    "\n",
    "        if tapaal_result == QueryResultStatus.unknown and not tapaal_search_result.timed_out:\n",
    "            tapaal_undecided += 1\n",
    "        if enhsp_result == QueryResultStatus.unknown:\n",
    "            enhsp_undecided += 1\n",
    "\n",
    "        if tapaal_result == QueryResultStatus.error:\n",
    "            tapaal_error += 1\n",
    "        if enhsp_result == QueryResultStatus.error:\n",
    "            enhsp_error += 1\n",
    "            errorsAtOnce = 0\n",
    "            if enhsp_search_result.get(\"OutOfMemory\", False):\n",
    "                enhspErrors[\"OutOfMemory\"]  += 1\n",
    "                errorsAtOnce += 1\n",
    "            if enhsp_search_result.get(\"StackOverflow\", False):\n",
    "                enhspErrors[\"StackOverflow\"]  += 1\n",
    "                errorsAtOnce += 1\n",
    "            if enhsp_search_result.get(\"SyntaxError\", False): \n",
    "                enhspErrors[\"SyntaxError\"]  += 1\n",
    "                errorsAtOnce += 1\n",
    "            if enhsp_search_result.get(\"TranslationFailed\", False):\n",
    "                enhspErrors[\"TranslationFailed\"]  += 1\n",
    "                errorsAtOnce += 1\n",
    "            if enhsp_search_result.get(\"NullPointerException\", False) and not enhsp_search_result.get(\"TranslationFailed\", False):\n",
    "                enhspErrors[\"NullPointerException\"]  += 1\n",
    "                errorsAtOnce += 1\n",
    "            errorsAtOnce\n",
    "\n",
    "            errorsAtOnce_translator = 0\n",
    "            if enhsp_translator_result.get(\"exprTooDeep_stringBuilder\", False):\n",
    "                enhspErrors_translator[\"exprTooDeep_stringBuilder\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"exprTooDeep_rawExpr\", False):\n",
    "                enhspErrors_translator[\"exprTooDeep_rawExpr\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"success\", False):\n",
    "                enhspErrors_translator[\"success\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"OutOfMemory\", False):\n",
    "                enhspErrors_translator[\"OutOfMemory\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"StackOverflow\", False) and not enhsp_translator_result.get(\"exprTooDeep_stringBuilder\", False) and not enhsp_translator_result.get(\"exprTooDeep_rawExpr\", False):\n",
    "                enhspErrors_translator[\"StackOverflow\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"NullPointerException\", False):\n",
    "                enhspErrors_translator[\"NullPointerException\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "            if enhsp_translator_result.get(\"PnmlParserError\", False):\n",
    "                enhspErrors_translator[\"PnmlParserError\"] += 1\n",
    "                errorsAtOnce_translator += 1\n",
    "\n",
    "            errorsAtOnce_translator\n",
    "\n",
    "        if tapaal_result == QueryResultStatus.satisfied and not enhsp_result == QueryResultStatus.satisfied:\n",
    "            satisfiable_uniquely_solved_tapaal += 1\n",
    "            if enhsp_result == QueryResultStatus.timeout:\n",
    "                satisfiable_uniquely_solved_tapaal_other_timed_out += 1\n",
    "\n",
    "        if enhsp_result == QueryResultStatus.satisfied and not tapaal_result == QueryResultStatus.satisfied:\n",
    "            satisfiable_uniquely_solved_enhsp += 1\n",
    "            if tapaal_search_result and tapaal_search_result.timed_out:\n",
    "                satisfiable_uniquely_solved_enhsp_other_timed_out += 1\n",
    "\n",
    "            \n",
    "\n",
    "        if tapaal_result == QueryResultStatus.unsolvable and not enhsp_result == QueryResultStatus.unsolvable:\n",
    "            unsolvable_uniquely_solved_tapaal += 1\n",
    "            if enhsp_result == QueryResultStatus.timeout:\n",
    "                unsolvable_uniquely_solved_tapaal_other_timed_out += 1\n",
    "        if enhsp_result == QueryResultStatus.unsolvable and not tapaal_result == QueryResultStatus.unsolvable:\n",
    "            unsolvable_uniquely_solved_enhsp += 1\n",
    "            if tapaal_search_result and tapaal_search_result.timed_out:\n",
    "                unsolvable_uniquely_solved_enhsp_other_timed_out += 1\n",
    "\n",
    "\n",
    "\n",
    "        if enhsp_search_result and enhsp_search_result.plan_warning:\n",
    "            possiblyInvalidSolutionsTotal += 1\n",
    "                                \n",
    "        # Agree on solvable\n",
    "        if tapaal_result == QueryResultStatus.satisfied and enhsp_result == QueryResultStatus.satisfied and not enhsp_search_result.plan_warning:\n",
    "            totalAgreedSolvable += 1\n",
    "            agreedSolvable +=1\n",
    "            if enhsp_search_time < tapaal_search_time:\n",
    "                enhspFasterSearchSolvable += 1\n",
    "            else:\n",
    "                tapaalFasterSearchSolvable += 1\n",
    "            if enhsp_translate_time + enhsp_search_time < tapaal_translate_time + tapaal_search_time:\n",
    "                enhspFasterTotalSolvable += 1\n",
    "            else:\n",
    "                tapaalFasterTotalSolvable += 1\n",
    "\n",
    "            if enhsp_search_result and enhsp_search_result.plan_warning:\n",
    "                possiblyInvalidSolutionsInAgreed += 1\n",
    "\n",
    "        # Agree on unsolvable\n",
    "        if tapaal_result == QueryResultStatus.unsolvable and enhsp_result == QueryResultStatus.unsolvable:\n",
    "            totalAgreedUnsolvable += 1\n",
    "            agreedUnsolvable += 1\n",
    "            if enhsp_search_time < tapaal_search_time:\n",
    "                 enhspFasterSearchUnsolvable += 1\n",
    "            else:\n",
    "                tapaalFasterSearchUnsolvable += 1\n",
    "\n",
    "            if enhsp_translate_time + enhsp_search_time < tapaal_translate_time + tapaal_search_time:\n",
    "                 enhspFasterTotalUnsolvable += 1\n",
    "            else:\n",
    "                tapaalFasterTotalUnsolvable += 1\n",
    "        \n",
    "        if tapaal_search_result and tapaal_search_result.timed_out:\n",
    "            tapaal_timed_out += 1\n",
    "        if enhsp_result == QueryResultStatus.timeout:\n",
    "            enhsp_timed_out += 1\n",
    "    \n",
    "    # Skip boring domains\n",
    "    if disagreeCount == 0 and agreedSolvable and agreedUnsolvable == 0:\n",
    "        continue\n",
    "\n",
    "    print(domain_name)\n",
    "    print(\"\\tSolvable:\", agreedSolvable, \"Unsolvable:\", agreedUnsolvable, \"disagreed on:\", disagreeCount)\n",
    "    if disagreeCount > 0:\n",
    "        print(\"\\ttapaal\", success_states[\"tapaal\"])\n",
    "        print(\"\\tenhsp\", success_states[\"enhsp\"])\n",
    "\n",
    "\n",
    "print(f\"ENHSP warnings in agreed: {possiblyInvalidSolutionsInAgreed}\")\n",
    "print(f\"ENHSP warnings in total: {possiblyInvalidSolutionsTotal}\")\n",
    "\n",
    "print(f\"Solved by Tapaal: {solvedTotalTapaal}\")\n",
    "print(f\"Solved by Enhsp: {solvedTotalEnhsp}\")\n",
    "print(f\"Total agreed solvable: {totalAgreedSolvable}\")\n",
    "\n",
    "print(f\"Tapaal Faster Search solvable: {tapaalFasterSearchSolvable}\")\n",
    "print(f\"Tapaal Faster Total solvable: {tapaalFasterTotalSolvable}\")\n",
    "print(f\"ENHSP Faster Search solvable: {enhspFasterSearchSolvable}\")\n",
    "print(f\"ENHSP Faster Total solvable: {enhspFasterTotalSolvable}\")\n",
    "\n",
    "print(f\"Unsolved by Tapaal: {unsolvedTotalTapaal}\")\n",
    "print(f\"Unsolved by Enhsp: {unsolvedTotalEnhsp}\")\n",
    "print(f\"Total agreed unsolvable: {totalAgreedUnsolvable}\")\n",
    "print(f\"Tapaal Faster Search unsolvable: {tapaalFasterSearchUnsolvable}\")\n",
    "print(f\"Tapaal Faster Total unsolvable: {tapaalFasterTotalUnsolvable}\")\n",
    "print(f\"ENHSP Faster Search unsolvable: {enhspFasterSearchUnsolvable}\")\n",
    "print(f\"ENHSP Faster Total unsolvable: {enhspFasterTotalUnsolvable}\")\n",
    "\n",
    "\n",
    "print(f\"satisfiable_uniquely_solved_tapaal: {satisfiable_uniquely_solved_tapaal}\")\n",
    "print(f\"satisfiable_uniquely_solved_enhsp: {satisfiable_uniquely_solved_enhsp}\")\n",
    "print(f\"unsolvable_uniquely_solved_tapaal: {unsolvable_uniquely_solved_tapaal}\")\n",
    "print(f\"unsolvable_uniquely_solved_enhsp: {unsolvable_uniquely_solved_enhsp}\")\n",
    "\n",
    "print(f\"satisfiable_uniquely_solved_tapaal_other_timed_out:\", satisfiable_uniquely_solved_tapaal_other_timed_out)\n",
    "print(f\"satisfiable_uniquely_solved_enhsp_other_timed_out:\", satisfiable_uniquely_solved_enhsp_other_timed_out)\n",
    "print(f\"unsolvable_uniquely_solved_tapaal_other_timed_out:\", unsolvable_uniquely_solved_tapaal_other_timed_out)\n",
    "print(f\"unsolvable_uniquely_solved_enhsp_other_timed_out:\", unsolvable_uniquely_solved_enhsp_other_timed_out)\n",
    "\n",
    "\n",
    "print(f\"tapaal_undecided: {tapaal_undecided}\")\n",
    "print(f\"enhsp_undecided: {enhsp_undecided}\")\n",
    "\n",
    "print(f\"tapaal_error: {tapaal_error}\")\n",
    "print(f\"enhsp_error: {enhsp_error}\")\n",
    "print(f\"enhspErrors_translator: {enhspErrors_translator}\")\n",
    "print(f\"enhspErrors: \", enhspErrors)\n",
    "\n",
    "print(f\"tapaal_timed_out:\", tapaal_timed_out)\n",
    "print(f\"enhsp_timed_out:\", enhsp_timed_out)\n",
    "\n",
    "print(\"Total Domains: \", total_domains)\n",
    "print(\"Total Queries: \", total_queries)\n",
    "\n",
    "print(\"table:\", \"tapaal\", \"enhsp\")\n",
    "print(\"Satisfiable Queries Answered:                   \", solvedTotalTapaal, f\"{solvedTotalEnhsp} + {possiblyInvalidSolutionsTotal} flagged\")\n",
    "print(\"Satisfiable Uniquely Answered:                  \", satisfiable_uniquely_solved_tapaal, satisfiable_uniquely_solved_enhsp)\n",
    "print(\"Satisfiable Uniquely Answered: (other timed out)\", satisfiable_uniquely_solved_tapaal_other_timed_out, satisfiable_uniquely_solved_enhsp_other_timed_out)\n",
    "print(\"Satisfiable Total Faster:                       \", tapaalFasterTotalSolvable, enhspFasterTotalSolvable)\n",
    "print(\"Satisfiable Total Faster:                       \", tapaalFasterSearchSolvable, enhspFasterSearchSolvable)\n",
    "print(\"---\")\n",
    "print(\"Unsolvable Queries Answered:                    \", unsolvedTotalTapaal, unsolvedTotalEnhsp)\n",
    "print(\"Unsolvable Uniquely Answered:                   \", unsolvable_uniquely_solved_tapaal, unsolvable_uniquely_solved_enhsp)\n",
    "print(\"Unsolvable Uniquely Answered: (other timed out) \", unsolvable_uniquely_solved_tapaal_other_timed_out, unsolvable_uniquely_solved_enhsp_other_timed_out)\n",
    "print(\"Unsolvable Total Faster:                        \", tapaalFasterTotalUnsolvable, enhspFasterTotalUnsolvable)\n",
    "print(\"Unsolvable Search Faster:                       \", tapaalFasterSearchUnsolvable, enhspFasterSearchUnsolvable)\n",
    "print(\"---\")\n",
    "print(\"Timed Out:                                      \", tapaal_timed_out, enhsp_timed_out)\n",
    "print(\"Error:                                          \", tapaal_error, enhsp_error)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "reductions = dict()\n",
    "domains_per_reduction = dict()\n",
    "\n",
    "\n",
    "for translator_name, translator_results in results.translators.items():\n",
    "    # if translator_name == \"colored\": continue\n",
    "    # if translator_name == \"colored_hierarchy\": continue\n",
    "    if translator_name == \"grounded\": continue\n",
    "    if translator_name == \"downward\": continue\n",
    "\n",
    "    for searcher_name, searcher_results in translator_results.searchers.items():\n",
    "        for domain_name, result_collections in searcher_results.domains.items():\n",
    "\n",
    "            for domain_sub_id, search_results in enumerate(result_collections.search_results):\n",
    "                \n",
    "                if len(result_collection.search_results) == 0:\n",
    "                    continue\n",
    "\n",
    "                search_result = result_collection.search_results[0]\n",
    "                if hasattr(search_result, \"reductions_applied\"):\n",
    "                    for (rule_id, count) in search_result.reductions_applied.items():\n",
    "                        if not rule_id in reductions:\n",
    "                            reductions[rule_id] = 0\n",
    "                            domains_per_reduction[rule_id] = list()\n",
    "                        \n",
    "                        reductions[rule_id] += count\n",
    "                        if count > 0:\n",
    "                            domains_per_reduction[rule_id].append(f\"{translator.name}:{domain_name.name}_{domain_sub_id}\")\n",
    "    \n",
    "    #print(test_case.name)\n",
    "for (reduction_id, count) in reductions.items():\n",
    "    print(str.ljust(f\"{reduction_id}: {count}\", 30) + f\"{domains_per_reduction[rule_id]}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# -r 3 2,3,4,6,8,11,12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview Plot\n",
    "plot = run config\n",
    "\n",
    "x = IPC instance id\n",
    "\n",
    "y = median time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_runner.analysers import TranslatorResult, SearchResult\n",
    "from result_collection import result_collection\n",
    "\n",
    "# Generic\n",
    "\n",
    "\n",
    "def median_reduction(translator_reduction: Callable[[TranslatorResult], float], searcher_reduction: Callable[[SearchResult], float]) -> Callable[[result_collection], list[float]]:\n",
    "    def reduction(rc: result_collection) -> list[float]:\n",
    "        translator_vals_per_task = [[translator_reduction(x) for x in translator_results] for translator_results in rc.translator_results]\n",
    "        search_vals_per_task     = [[searcher_reduction(x) for x in search_results] for search_results in rc.search_results]\n",
    "\n",
    "\n",
    "        translator_numeric = [statistics.median(results) if len(results) > 0 else infinite for results in translator_vals_per_task]\n",
    "        searcher_numeric   = [statistics.median(results) if len(results) > 0 else infinite for results in search_vals_per_task]\n",
    "\n",
    "\n",
    "        added = [ x + y for x, y in zip(translator_numeric, searcher_numeric)]\n",
    "\n",
    "        return added\n",
    "    \n",
    "    return reduction\n",
    "\n",
    "\n",
    "def minimum_reduction(translator_reduction: Callable[[TranslatorResult], float], searcher_reduction: Callable[[SearchResult], float]) -> Callable[[result_collection], list[float]]:\n",
    "    def reduction(rc: result_collection) -> list[float]:\n",
    "        translator_vals_per_task = [[translator_reduction(x) for x in translator_results] for translator_results in rc.translator_results]\n",
    "        search_vals_per_task     = [[searcher_reduction(x) for x in search_results] for search_results in rc.search_results]\n",
    "\n",
    "\n",
    "        translator_numeric = [statistics.median(results) if len(results) > 0 else infinite for results in translator_vals_per_task]\n",
    "        searcher_numeric   = [statistics.median(results) if len(results) > 0 else infinite for results in search_vals_per_task]\n",
    "\n",
    "\n",
    "        added = [ x + y for x, y in zip(translator_numeric, searcher_numeric)]\n",
    "\n",
    "        return added\n",
    "    \n",
    "    return reduction\n",
    "\n",
    "\n",
    "def median_search_property(prop_name: str) -> Callable[[result_collection], list[float]]:\n",
    "    return median_reduction(\n",
    "        lambda res: 0,\n",
    "        lambda res: res.get(prop_name, infinite)\n",
    "    )\n",
    "\n",
    "\n",
    "# Time\n",
    "\n",
    "median_time_total = median_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "minimum_time_search = minimum_reduction(\n",
    "    lambda res: 0,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "median_time_translate = minimum_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.valid_translation else infinite,\n",
    "    lambda res: 0\n",
    ")\n",
    "\n",
    "median_time_search = median_reduction(\n",
    "    lambda res: 0,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "minimum_time_total = minimum_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if res.has_plan else infinite\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total time scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "solved_median_time_total = median_reduction(\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user,\n",
    "    lambda res: res.time.seconds_system + res.time.seconds_user if (res.result_status == QueryResultStatus.satisfied  or res.result_status == QueryResultStatus.unsolvable) else infinite\n",
    ")\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "styles = []\n",
    "\n",
    "for domain_name, domain_results in results.domains.items():\n",
    "    tapaal = domain_results.translators[\"nothing\"].searchers[\"Tapaal\"]\n",
    "    enhsp = domain_results.translators[\"cpn\"].searchers[\"CpnToEnhsp\"]\n",
    "\n",
    "    tapaal_time = solved_median_time_total(tapaal)\n",
    "    enshp_time = solved_median_time_total(enhsp)\n",
    "\n",
    "    for i in range(0, 31):\n",
    "        # Experiment actually exists if Tapaal had a translation\n",
    "        if not tapaal.translator_results[i]:\n",
    "            continue\n",
    "\n",
    "        if tapaal_time[i] == infinite and enshp_time[i] == infinite:\n",
    "            continue # Would just be in top right\n",
    "\n",
    "        status_provider = tapaal.search_results[i][0]\n",
    "        if status_provider.result_status == QueryResultStatus.error:\n",
    "            status_provider = enhsp.search_results[i][0]\n",
    "\n",
    "        \n",
    "        solvable = status_provider.result_status == QueryResultStatus.satisfied\n",
    "        unsolvable = status_provider.result_status == QueryResultStatus.unsolvable\n",
    "        #unknown = status_provider.result_status == QueryResultStatus.unknown\n",
    "        error = status_provider.result_status == QueryResultStatus.error\n",
    "        warning = enhsp.search_results[i][0].plan_warning\n",
    "\n",
    "        style = (\n",
    "            (\"x\", \"#A00\") if warning else\n",
    "            (\"^\", \"#0A0\") if solvable else\n",
    "            (\"H\", \"#00A\") if unsolvable else\n",
    "            #(\"o\", \"#222\") if unknown else\n",
    "            (\"s\", \"#FF0\") if error else\n",
    "                None\n",
    "        )\n",
    "        if not style:\n",
    "            raise \"Unhandled State\"\n",
    "        \n",
    "        styles.append(style)\n",
    "\n",
    "        x.append(tapaal_time[i])\n",
    "        y.append(enshp_time[i])\n",
    "\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_x = max([i for i in x if i != infinite])\n",
    "max_y = max([i for i in y if i != infinite])\n",
    "max_max = max(max_x, max_y)\n",
    "\n",
    "unsolvedVal = 10**5 # max_max * 3\n",
    "plot_max = max(max_max, unsolvedVal)\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(scale, scale))\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "shapes, colors = zip(*styles)\n",
    "\n",
    "ax.plot([0, plot_max], [0, plot_max])\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plotX = x[i] if x[i] != infinite else unsolvedVal\n",
    "    plotY = y[i] if y[i] != infinite else unsolvedVal\n",
    "\n",
    "    ax.scatter(plotX, plotY, c=colors[i], marker=shapes[i])#, vmin=0, vmax=100)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Total seconds TAPAAL\")\n",
    "plt.ylabel(\"Total seconds ENHSP\")\n",
    "\n",
    "ax.set_xlim(xmin=0.001, xmax=plot_max)\n",
    "ax.set_ylim(ymin=0.001, ymax=plot_max)\n",
    "\n",
    "\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[-2] = 'Undecided'\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "labels[-2] = 'Undecided'\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "\n",
    "warning    = Line2D([0], [0], label='warning',      marker=\"x\", c=\"#A00\", markersize=10, markerfacecolor=\"#A00\", linestyle='')\n",
    "solvable   = Line2D([0], [0], label='Satisfiable',  marker=\"^\", c=\"#0A0\", markersize=10, markerfacecolor=\"#0A0\", linestyle='')\n",
    "unsolvable = Line2D([0], [0], label='Unsolvable',   marker=\"H\", c=\"#00A\", markersize=10, markerfacecolor=\"#00A\", linestyle='')\n",
    "\n",
    "\n",
    "plt.legend(handles=[warning, solvable, unsolvable], loc=\"lower right\")\n",
    "\n",
    "# plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_save_dir, f\"cpnToPddlResults_Total.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old cactus plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# class XTickFormater(matplotlib.ticker.Formatter):\n",
    "#     def format_ticks(values):\n",
    "#         return [f\"P{v+1}\" for v in values]\n",
    "# xtickFormatter = XTickFormater()\n",
    "# Formerly 1+ to x axis\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_overview_cactus_plot(name: str, description: str, reduction: Callable[[\"result_collection\"], list[float]]):\n",
    "    fig_rows = 5\n",
    "    fig_cols = 10\n",
    "\n",
    "\n",
    "    # Domain -> searcher -> translator -> IPCMedian[] \n",
    "    # search_results_domain_searcher_translator_test_case\n",
    "\n",
    "\n",
    "    i=1\n",
    "    # scale = 4.5\n",
    "    scale = 10\n",
    "    # fig = plt.figure(figsize=(2.3*scale, scale))\n",
    "    fig = plt.figure(figsize=(scale, scale))\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "\n",
    "    for domain_name, domain_results in results.domains.items():\n",
    "\n",
    "\n",
    "        subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "        max_y = 0\n",
    "        axis = plt.gca()\n",
    "\n",
    "        for translator_name, translator_results in domain_results.translators.items():\n",
    "            for searcher_name, _result_collection in translator_results.searchers.items():\n",
    "\n",
    "                #plt.plot(list(median_times.values())[0], 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                # plt.plot(median_times, 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                reduced_data = reduction(_result_collection)\n",
    "                if _result_collection.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "                    \n",
    "                    plt.plot(reduced_data, _result_collection.style, color=_result_collection.color, label=_result_collection.display_name)#f\"{translator.name}({searcher.name})\")\n",
    "\n",
    "                    #plt.xticks(range(0,30), [f\"P{x+1}\" for x in range(0,30)])\n",
    "                    # plt.xlabels([f\"P{x+1}\" for x in range(0,30)])\n",
    "                    #(xlim_min, xlim_max) = axis.get_xlim()\n",
    "                    #axis.set_xlim([xlim_min, min(xlim_max, 30)])\n",
    "\n",
    "                    # yaxis begins at 0\n",
    "                    #(ylim_min, ylim_max) = axis.get_ylim()\n",
    "                    max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                    subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                    subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "                    # subplt.axes.ticklabel_format(xtickFormatter, \"x\")\n",
    "                    # fig.gca().axes.xaxis.format_ticks(xtickFormatter)\n",
    "                #yticks = range(0,30)\n",
    "                #plt.yticks(yticks, step=1)\n",
    "#                ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # Integer x axis\n",
    "\n",
    "        # axis.set_ylim(bottom=0)\n",
    "\n",
    "        plt.title(domain_name)\n",
    "        #plt.title(f'{description} - {test_case.name}')\n",
    "        plt.gca().legend(loc='best')\n",
    "        plt.xlabel('Task index')\n",
    "        if (i-1)%3 == 0:\n",
    "            plt.ylabel(description)\n",
    "        subplt.set_yscale(\"log\")\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_save_dir, f\"{name}.png\"))\n",
    "\n",
    "\n",
    "\n",
    "make_overview_cactus_plot(\"overview_med_time_total\", 'Median Time (sec)', median_time_total)\n",
    "make_overview_cactus_plot(\"overview_min_time_total\", \"Min Total Time\", minimum_time_total)\n",
    "make_overview_cactus_plot(\"overview_min_time_search\", \"Min Search Time\", minimum_time_search)\n",
    "\n",
    "\n",
    "\n",
    "# #make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "# #make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "# make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "# #make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "# #make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "# make_overview_cactus_plot(\"overview_verification_time\", \"Median Verification Time\", lambda res: res.median_verification_time)\n",
    "# # make_overview_cactus_plot(\"overview_unfolded_places\", \"Unfolded Place Count\", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "# # make_overview_cactus_plot(\"overview_unfolded_transitions\", \"Unfolded Transition Count\", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Domain Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_domain_cactus_plot(name: str, description: str, rows, cols, reductions: list[tuple[str, Callable[[\"result_collection\"], list[float]]]]):\n",
    "    fig_rows = rows #1\n",
    "    fig_cols = cols #len(reductions)\n",
    "\n",
    "    scale = 10\n",
    "\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "    for (domain_name, domain_results) in results.domains.items():\n",
    "        fig = plt.figure(figsize=(scale, scale))\n",
    "        i=1\n",
    "        for (reduction_name, reduction) in reductions:\n",
    "            subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "            max_y = 0\n",
    "            axis = plt.gca()\n",
    "            for (translator, translator_results) in domain_results.translators.items():\n",
    "                for (searcher, resultCollections) in translator_results.searchers.items():\n",
    "                    reduced_data = reduction(resultCollections)\n",
    "                    if resultCollections.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "\n",
    "                        # if searcher.display_name != \"color_rpfs_safe_no_timeout\" and searcher.display_name != \"hier_rpfs_safe_no_timeout\" and searcher.display_name != \"grounded\":\n",
    "                        #     continue\n",
    "                        \n",
    "                        plt.plot(reduced_data, resultCollections.style, color=resultCollections.color, label=resultCollections.display_name)\n",
    "\n",
    "                        max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                        subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                        subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "            plt.title(reduction_name)\n",
    "            #plt.title(f'{description} - {test_case.name}')\n",
    "            plt.gca().legend(loc='best')\n",
    "            plt.xlabel('Task index')\n",
    "            if (i-1)%4 == 0:\n",
    "                plt.ylabel(domain_name)\n",
    "            subplt.set_yscale(\"log\")\n",
    "            i += 1\n",
    "\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_save_dir, f\"{name}_{domain_name}.png\"))\n",
    "\n",
    "#make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "#make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "#make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "\n",
    "reductions:list[tuple[str, Callable[[\"result_collection\"], float]]] = {\n",
    "    ('Median Time (sec)', median_time_total),\n",
    "    (\"Median Search Time (sec)\", median_time_search),\n",
    "    (\"Median Translate Time (sec)\", median_time_translate),\n",
    "    # (\"Median Verification Time\",  median_search_property(\"time_verification\")),\n",
    "    (\"Unfolded Place Count\", median_search_property(\"place_count_after_reduction\")),\n",
    "    (\"Unfolded Transition Count\", median_search_property(\"transition_count_after_reduction\"))\n",
    "}\n",
    "\n",
    "make_domain_cactus_plot(\"name\", \"description\", 3, 2, reductions)\n",
    "# make_domain_cactus_plot(\"name\", \"description\", 2, 2, reductions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_time              \", \"Min Total Time                     \", lambda res: res.min_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# min_verificaiton_time \", 'Min verification time              ', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# time                  \", 'Median Time (sec)                  ', lambda res: res.median_time)\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "# make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "def get_median_time_minus_unfolding(res: ResultCollection):\n",
    "                \n",
    "                \n",
    "                if translator.name==\"colored\":\n",
    "                \n",
    "                plan_lengths = [len(result.plan.actions) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_trace_length = statistics.median(plan_lengths)\n",
    "\n",
    "                time_unfolding = [result[\"time_unfolding\"] if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_unfolding_time = statistics.median(time_unfolding)\n",
    "\n",
    "                resultCollection.median_time_minus_unfolding = statistics.median([(result.time.seconds_system + result.time.seconds_user - result[\"time_unfolding\"]) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ])\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median unfolding Time (sec)        ', lambda res: res.median_unfolding_time)\n",
    "\n",
    "\n",
    "# verification_time     \", \"Median Verification Time           \", lambda res: res.median_verification_time)\n",
    "\n",
    "\n",
    "# unfolded_places       \", \"Unfolded Place Count               \", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "\n",
    "\n",
    "# unfolded_transitions  \", \"Unfolded Transition Count          \", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from typing import Callable\n",
    "import re\n",
    "from math import floor\n",
    "import statistics\n",
    "\n",
    "from test_runner import *\n",
    "from test_runner.translators import *\n",
    "from test_runner.analysers import SearchResult\n",
    "\n",
    "\n",
    "# from test_runner import TestCase, BaseTestRunner, LiftedPlanningRunner, GroundedPlanningRunner\n",
    "# from test_runner.tapaal_caller import QueryResult\n",
    "\n",
    "from parse_results import translator_result_type, search_result_type#, load_translator_results, load_search_results, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downward = circle red\n",
    "# grounded = square green\n",
    "# lifted = triangle blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infinite = float(\"inf\")\n",
    "\n",
    "\n",
    "results_dir = \"./results\"\n",
    "plot_save_dir = \"./results/plots\"\n",
    "\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "results_path = \"./results\"\n",
    "\n",
    "def load_translator_results() -> translator_result_type:\n",
    "    with open(os.path.join(results_path, f\"translator_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def load_search_results() -> search_result_type:\n",
    "    with open(os.path.join(results_path, f\"search_results.pickle\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "\n",
    "translator_results: translator_result_type = load_translator_results()\n",
    "search_results: search_result_type = load_search_results()\n",
    "\n",
    "# searcher -> translator -> test_case\n",
    "search_results_search_translator_test_case: dict[\"BaseSearcher\", dict[\"BaseTranslator\", dict[\"TestCase\", list[\"SearchResult\"]]]] = dict()\n",
    "for translator, translator_results in search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for search, results in test_results.items():\n",
    "            search_results_search_translator_test_case[search] = search_results_search_translator_test_case.get(search, dict())\n",
    "            search_results_search_translator_test_case[search][translator] = search_results_search_translator_test_case[search].get(translator, dict())\n",
    "            search_results_search_translator_test_case[search][translator][test_case] = results\n",
    "\n",
    "\n",
    "# test_case -> searcher -> translator\n",
    "search_results_test_case_searcher_translator: dict[\"TestCase\", dict[\"BaseSearcher\", dict[\"BaseTranslator\", list[\"SearchResult\"]]]] = dict()\n",
    "for translator, translator_results in search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for search, results in test_results.items():\n",
    "            search_results_test_case_searcher_translator[test_case] = search_results_test_case_searcher_translator.get(test_case, dict())\n",
    "            search_results_test_case_searcher_translator[test_case][search] = search_results_test_case_searcher_translator[test_case].get(search, dict())\n",
    "            search_results_test_case_searcher_translator[test_case][search][translator] = results\n",
    "\n",
    "\n",
    "#def median(numbers: list[float], total_length: int) -> float:\n",
    "\n",
    "\n",
    "class ResultCollection(object):\n",
    "    is_tapaal: bool = False\n",
    "    raw: list[SearchResult]\n",
    "    median_time: float = infinite\n",
    "    median_unfolding_time: float = infinite\n",
    "    median_verification_time: float = infinite\n",
    "    median_trace_length: int = infinite\n",
    "    \n",
    "\n",
    "domain_regex = re.compile(r\"^(?P<domain>.+?)_(?P<id>\\d\\d)$\", re.MULTILINE)\n",
    "\n",
    "# Domain -> translator -> searcher-> IPCMedianTime[] \n",
    "search_results_domain_translator_medians: dict[\"str\", dict[\"BaseTranslator\", dict[\"BaseSearcher\", dict[\"int\", list[\"ResultCollection\"]]]]] = dict()\n",
    "for translator, translator_results in search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for search, results in test_results.items():\n",
    "            if (len(results)==0):\n",
    "                continue\n",
    "\n",
    "            domain_name = domain_regex.match(test_case.name)[\"domain\"]\n",
    "            domain_problem_id = int(domain_regex.match(test_case.name)[\"id\"])\n",
    "\n",
    "            # times = [(result.time.seconds_system + result.time.seconds_user) for result in results if result.get(\"has_plan\", False)]\n",
    "            # times.sort()\n",
    "            # mid = floor(len(results)/2)-1\n",
    "            # time_median =  times[mid] if len(times)-1 > mid else float('inf')\n",
    "\n",
    "            resultCollection = ResultCollection()\n",
    "            resultCollection.raw = results\n",
    "\n",
    "\n",
    "            times = [(result.time.seconds_system + result.time.seconds_user) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "            resultCollection.median_time = statistics.median(times)\n",
    "            resultCollection.median_time_minus_unfolding = resultCollection.median_time\n",
    "            resultCollection.min_time = min(times)\n",
    "\n",
    "            if translator.name==\"colored\" or translator.name==\"grounded\":\n",
    "                is_tapaal = True\n",
    "\n",
    "                verification_times = [result[\"time_verification\"] if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_verification_time = statistics.median(verification_times)\n",
    "\n",
    "            if translator.name==\"colored\":\n",
    "                \n",
    "                plan_lengths = [len(result.plan.actions) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_trace_length = statistics.median(plan_lengths)\n",
    "\n",
    "                time_unfolding = [result[\"time_unfolding\"] if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_unfolding_time = statistics.median(time_unfolding)\n",
    "\n",
    "                resultCollection.median_time_minus_unfolding = statistics.median([(result.time.seconds_system + result.time.seconds_user - result[\"time_unfolding\"]) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ])\n",
    "\n",
    "\n",
    "            search_results_domain_translator_medians[domain_name] = search_results_domain_translator_medians.get(domain_name, dict())\n",
    "            search_results_domain_translator_medians[domain_name][translator] = search_results_domain_translator_medians[domain_name].get(translator, dict())\n",
    "            search_results_domain_translator_medians[domain_name][translator][search] = search_results_domain_translator_medians[domain_name][translator].get(search, [float('inf') for x in list(range(0,30))])\n",
    "            search_results_domain_translator_medians[domain_name][translator][search][domain_problem_id-1] = resultCollection\n",
    "\n",
    "\n",
    "# Domain -> translator -> searcher-> IPCMedianPlan[] \n",
    "#search_results_domain_translator_medians: dict[\"str\", dict[\"TestCase\", dict[\"BaseSearcher\", dict[\"BaseTranslator\", list[\"SearchResult\"]]]]] = dict()\n",
    "for translator, translator_results in search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for search, results in test_results.items():\n",
    "\n",
    "            break\n",
    "            \n",
    "\n",
    "            domain_name = domain_regex.match(test_case.name)[\"domain\"]\n",
    "            domain_problem_id = int(domain_regex.match(test_case.name)[\"id\"])\n",
    "\n",
    "\n",
    "            plan_len = [(result.plan.actions) for result in results if result.get(\"has_plan\", False)]\n",
    "            times = [(result.time.seconds_system + result.time.seconds_user) for result in results if result.get(\"has_plan\", False)]\n",
    "            times.sort()\n",
    "            mid = floor(len(results)/2)\n",
    "            time_median =  times[mid] if len(times)-1 > mid else float('inf')\n",
    "            \n",
    "\n",
    "            search_results_domain_translator_medians[domain_name] = search_results_domain_translator_medians.get(domain_name, dict())\n",
    "            search_results_domain_translator_medians[domain_name][translator] = search_results_domain_translator_medians[domain_name].get(translator, dict())\n",
    "            search_results_domain_translator_medians[domain_name][translator][search] = search_results_domain_translator_medians[domain_name][translator].get(search, [float('inf') for x in list(range(0,30))])\n",
    "            search_results_domain_translator_medians[domain_name][translator][search][domain_problem_id] = time_median\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for translator, translator_results in search_results.items():\n",
    "    for test_case, test_results in translator_results.items():\n",
    "        for search, results in test_results.items():\n",
    "            if search.name == \"no_color_optimizations\":\n",
    "                search.style = None\n",
    "                continue\n",
    "\n",
    "            if translator.name == \"colored\" and search.name == \"rpfs\":\n",
    "                search.style = \"s-\"\n",
    "                search.color=\"#1b9e77\"\n",
    "                continue\n",
    "\n",
    "            if translator.name == \"grounded\" and search.name == \"rpfs\":\n",
    "                search.style = \"v-\"\n",
    "                search.color=\"#d95f02\"\n",
    "                continue\n",
    "\n",
    "            if translator.name == \"downward\" and search.name == \"lama_first\":\n",
    "                search.style = \"o-\"\n",
    "                search.color=\"#7570b3\"\n",
    "                continue\n",
    "\n",
    "            print(\"Unstyled config\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cactus Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "def make_cactus_plot(name: str, description: str, reduction: Callable[[\"SearchResult\"], float]):\n",
    "    fig_rows = 8\n",
    "    fig_cols = 6\n",
    "\n",
    "\n",
    "    i=1\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    for (test_case, test_case_results) in search_results_test_case_searcher_translator.items():\n",
    "        subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "        for (searcher, searcher_results) in test_case_results.items():\n",
    "            for (translator, results) in searcher_results.items():\n",
    "                times = [reduction(res) for res in results if \"has_plan\" in res]\n",
    "                times.sort()\n",
    "                #median = times[int(len(times)/2)]\n",
    "                median_str = f\"{times[int(len(times)/2)]:.4f}\" if len(times) > 0 else \"N/A\"\n",
    "                plt.plot(times, 'o-', label=f\"{translator.name}({searcher.name}) - median={median_str}\")\n",
    "                for res in results:\n",
    "                    print(res)\n",
    "\n",
    "        plt.title(f'{description} - {test_case.name}')\n",
    "        plt.gca().legend(loc='best')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Time (sec)')\n",
    "        subplt.set_yscale(\"log\")\n",
    "        i += 1\n",
    "\n",
    "    plt.savefig(os.path.join(plot_save_dir, f\"{name}.png\"))\n",
    "\n",
    "# make_cactus_plot(\"total_time\", \"System + User time\", lambda res: res.time.seconds_system + res.time.seconds_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "def make_cactus_plot(name: str, description: str, reduction: Callable[[\"SearchResult\"], float]):\n",
    "    fig_rows = 8\n",
    "    fig_cols = 6\n",
    "\n",
    "\n",
    "    i=1\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    for (test_case, test_case_results) in search_results_test_case_searcher_translator.items():\n",
    "        subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "        for (searcher, searcher_results) in test_case_results.items():\n",
    "            for (translator, results) in searcher_results.items():\n",
    "                times = [reduction(res) for res in results if \"has_plan\" in res]\n",
    "                times.sort()\n",
    "                #median = times[int(len(times)/2)]\n",
    "#                median_str = f\"{times[int(len(times)/2)]:.4f}\" if len(times) > 0 else \"N/A\"\n",
    "#                plt.plot(times, 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                plt.plot(times, 'o-')\n",
    "                #for res in results:\n",
    "                #    print(res)\n",
    "\n",
    "        plt.title(test_case.name)\n",
    "        #plt.title(f'{description} - {test_case.name}')\n",
    "        plt.gca().legend(loc='best')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Time (sec)')\n",
    "        subplt.set_yscale(\"log\")\n",
    "        i += 1\n",
    "\n",
    "    plt.title(description)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_save_dir, f\"{name}.png\"))\n",
    "\n",
    "# make_cactus_plot(\"total_time\", \"System + User time\", lambda res: res.time.seconds_system + res.time.seconds_user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview Plot\n",
    "plot = run config\n",
    "\n",
    "x = IPC instance id\n",
    "\n",
    "y = median time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# class XTickFormater(matplotlib.ticker.Formatter):\n",
    "#     def format_ticks(values):\n",
    "#         return [f\"P{v+1}\" for v in values]\n",
    "# xtickFormatter = XTickFormater()\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{1+x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_overview_cactus_plot(name: str, description: str, reduction: Callable[[\"ResultCollection\"], float]):\n",
    "    fig_rows = 3\n",
    "    fig_cols = 3\n",
    "\n",
    "\n",
    "    # Domain -> searcher -> translator -> IPCMedian[] \n",
    "    # search_results_domain_searcher_translator_test_case\n",
    "\n",
    "\n",
    "    i=1\n",
    "    # scale = 4.5\n",
    "    scale = 10\n",
    "    # fig = plt.figure(figsize=(2.3*scale, scale))\n",
    "    fig = plt.figure(figsize=(scale, scale))\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "    for (domain_name, domain_results) in search_results_domain_translator_medians.items():\n",
    "        subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "        max_y = 0\n",
    "        axis = plt.gca()\n",
    "\n",
    "        for (translator, translator_results) in domain_results.items():\n",
    "            for (searcher, resultCollections) in translator_results.items():\n",
    "                #plt.plot(list(median_times.values())[0], 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                # plt.plot(median_times, 'o-', label=f\"{translator.name}({searcher.name})\")\n",
    "                reduced_data = [reduction(x) for x in resultCollections]\n",
    "                if searcher.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "                    \n",
    "                    plt.plot(reduced_data, searcher.style, color=searcher.color, label=translator.name)#f\"{translator.name}({searcher.name})\")\n",
    "\n",
    "                    #plt.xticks(range(0,30), [f\"P{x+1}\" for x in range(0,30)])\n",
    "                    # plt.xlabels([f\"P{x+1}\" for x in range(0,30)])\n",
    "                    #(xlim_min, xlim_max) = axis.get_xlim()\n",
    "                    #axis.set_xlim([xlim_min, min(xlim_max, 30)])\n",
    "\n",
    "                    # yaxis begins at 0\n",
    "                    #(ylim_min, ylim_max) = axis.get_ylim()\n",
    "                    max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                    subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                    subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "                    # subplt.axes.ticklabel_format(xtickFormatter, \"x\")\n",
    "                    # fig.gca().axes.xaxis.format_ticks(xtickFormatter)\n",
    "                #yticks = range(0,30)\n",
    "                #plt.yticks(yticks, step=1)\n",
    "#                ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # Integer x axis\n",
    "\n",
    "        # axis.set_ylim(bottom=0)\n",
    "\n",
    "        plt.title(domain_name)\n",
    "        #plt.title(f'{description} - {test_case.name}')\n",
    "        plt.gca().legend(loc='best')\n",
    "        plt.xlabel('Task index')\n",
    "        if (i-1)%3 == 0:\n",
    "            plt.ylabel(description)\n",
    "        subplt.set_yscale(\"log\")\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_save_dir, f\"{name}.png\"))\n",
    "\n",
    "#make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "#make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "make_overview_cactus_plot(\"overview_verification_time\", \"Median Verification Time\", lambda res: res.median_verification_time)\n",
    "make_overview_cactus_plot(\"overview_unfolded_places\", \"Unfolded Place Count\", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "make_overview_cactus_plot(\"overview_unfolded_transitions\", \"Unfolded Transition Count\", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Domain Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System + User Time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "xtickFormatter = matplotlib.ticker.FuncFormatter(lambda x, pos: f\"P{1+x:02.0f}\")\n",
    "xtickLocator = matplotlib.ticker.MaxNLocator(integer=True)\n",
    "\n",
    "\n",
    "def make_domain_cactus_plot(name: str, description: str, rows, cols, reductions: list[tuple[str, Callable[[\"ResultCollection\"], float]]]):\n",
    "    fig_rows = rows #1\n",
    "    fig_cols = cols #len(reductions)\n",
    "\n",
    "\n",
    "\n",
    "    scale = 10\n",
    "\n",
    "#    ax = fig.gca()\n",
    "    # plt.title(description)\n",
    "    for (domain_name, domain_results) in search_results_domain_translator_medians.items():\n",
    "        fig = plt.figure(figsize=(scale, scale))\n",
    "        i=1\n",
    "        for (reduction_name, reduction) in reductions:\n",
    "            subplt = plt.subplot(fig_rows, fig_cols, i)\n",
    "            max_y = 0\n",
    "            axis = plt.gca()\n",
    "            for (translator, translator_results) in domain_results.items():\n",
    "                for (searcher, resultCollections) in translator_results.items():\n",
    "                    reduced_data = [reduction(x) for x in resultCollections]\n",
    "                    if searcher.style != None and len([x for x in reduced_data if x != infinite]) > 0:\n",
    "                        \n",
    "                        plt.plot(reduced_data, searcher.style, color=searcher.color, label=translator.name)#f\"{translator.name}({searcher.name})\")\n",
    "\n",
    "                        max_y = max(max_y, max([x for x in reduced_data if x != infinite]))\n",
    "\n",
    "\n",
    "                        subplt.xaxis.set_major_formatter(xtickFormatter)\n",
    "                        subplt.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "            plt.title(reduction_name)\n",
    "            #plt.title(f'{description} - {test_case.name}')\n",
    "            plt.gca().legend(loc='best')\n",
    "            plt.xlabel('Task index')\n",
    "            if (i-1)%4 == 0:\n",
    "                plt.ylabel(domain_name)\n",
    "            subplt.set_yscale(\"log\")\n",
    "            i += 1\n",
    "\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_save_dir, f\"{name}_{domain_name}.png\"))\n",
    "\n",
    "#make_overview_cactus_plot(\"overview_min_time\", \"Min Total Time\", lambda res: res.min_time)\n",
    "#make_overview_cactus_plot(\"overview_min_verificaiton_time\", 'Min verification time', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "#make_overview_cactus_plot(\"overview_time\", 'Median Time (sec)', lambda res: res.median_time)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "#make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median unfolding Time (sec)', lambda res: res.median_unfolding_time)\n",
    "\n",
    "reductions:list[tuple[str, Callable[[\"ResultCollection\"], float]]] = {\n",
    "    ('Median Time (sec)', lambda res: res.median_time),\n",
    "    (\"Median Verification Time\", lambda res: res.median_verification_time),\n",
    "    (\"Unfolded Place Count\", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite)),\n",
    "    (\"Unfolded Transition Count\", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n",
    "}\n",
    "\n",
    "make_domain_cactus_plot(\"name\", \"description\", 2, 2, reductions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_time              \", \"Min Total Time                     \", lambda res: res.min_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# min_verificaiton_time \", 'Min verification time              ', lambda resultCollection: min([res.get(\"time_verification\", infinite) for res in resultCollection.raw])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# time                  \", 'Median Time (sec)                  ', lambda res: res.median_time)\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "# make_overview_cactus_plot(\"overview_time_minus_unfolding\", 'Median Time (sec) - minus unfolding', lambda res: res.median_time_minus_unfolding)\n",
    "\n",
    "def get_median_time_minus_unfolding(res: ResultCollection):\n",
    "                \n",
    "                \n",
    "                if translator.name==\"colored\":\n",
    "                \n",
    "                plan_lengths = [len(result.plan.actions) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_trace_length = statistics.median(plan_lengths)\n",
    "\n",
    "                time_unfolding = [result[\"time_unfolding\"] if result.get(\"has_plan\", False) else float(\"inf\") for result in results ]\n",
    "                resultCollection.median_unfolding_time = statistics.median(time_unfolding)\n",
    "\n",
    "                resultCollection.median_time_minus_unfolding = statistics.median([(result.time.seconds_system + result.time.seconds_user - result[\"time_unfolding\"]) if result.get(\"has_plan\", False) else float(\"inf\") for result in results ])\n",
    "\n",
    "\n",
    "\n",
    "# time_minus_unfolding  \", 'Median unfolding Time (sec)        ', lambda res: res.median_unfolding_time)\n",
    "\n",
    "\n",
    "# verification_time     \", \"Median Verification Time           \", lambda res: res.median_verification_time)\n",
    "\n",
    "\n",
    "# unfolded_places       \", \"Unfolded Place Count               \", lambda resultCollection: resultCollection.raw[0].get(\"place_count_after_reduction\", infinite))\n",
    "\n",
    "\n",
    "# unfolded_transitions  \", \"Unfolded Transition Count          \", lambda resultCollection: resultCollection.raw[0].get(\"transition_count_after_reduction\", infinite))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
